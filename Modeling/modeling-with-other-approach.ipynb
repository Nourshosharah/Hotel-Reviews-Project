{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\n\n\n#for Nlp\nimport re, nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nfrom nltk import ngrams\nstop_words = list(set(stopwords.words('english')))\nwordnet_lemmatizer = WordNetLemmatizer()\n\n%matplotlib inline\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-07T07:15:49.170316Z","iopub.execute_input":"2022-06-07T07:15:49.170828Z","iopub.status.idle":"2022-06-07T07:15:49.962139Z","shell.execute_reply.started":"2022-06-07T07:15:49.170738Z","shell.execute_reply":"2022-06-07T07:15:49.961075Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# First approach\n## select random sampels from majority class  (here satsisfied=1) and equal as sample in another class (non satisfied here =0)","metadata":{}},{"cell_type":"code","source":"reviews_df=pd.read_csv('../input/modeling1-hotel-reviews/data_for_train_model.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:15:55.547183Z","iopub.execute_input":"2022-06-07T07:15:55.547894Z","iopub.status.idle":"2022-06-07T07:17:07.975952Z","shell.execute_reply.started":"2022-06-07T07:15:55.547848Z","shell.execute_reply":"2022-06-07T07:17:07.973980Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"reviews_df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"review_non_satisfied=reviews_df[reviews_df[\"satisfied\"]==0]\nreview_non_satisfied.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:17:07.984872Z","iopub.execute_input":"2022-06-07T07:17:07.987961Z","iopub.status.idle":"2022-06-07T07:17:08.376176Z","shell.execute_reply.started":"2022-06-07T07:17:07.987876Z","shell.execute_reply":"2022-06-07T07:17:08.375167Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"review_satisfied=reviews_df[reviews_df[\"satisfied\"]==1]\nreview_satisfied = review_satisfied.sample(n=14636)\nreview_satisfied.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:17:08.381430Z","iopub.execute_input":"2022-06-07T07:17:08.384301Z","iopub.status.idle":"2022-06-07T07:17:09.535199Z","shell.execute_reply.started":"2022-06-07T07:17:08.384240Z","shell.execute_reply":"2022-06-07T07:17:09.533883Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"frames = [review_satisfied, review_non_satisfied]\n  \nall_data = pd.concat(frames)\nall_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:17:09.538296Z","iopub.execute_input":"2022-06-07T07:17:09.538792Z","iopub.status.idle":"2022-06-07T07:17:10.325129Z","shell.execute_reply.started":"2022-06-07T07:17:09.538747Z","shell.execute_reply":"2022-06-07T07:17:10.323862Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport seaborn as sns\npalette = sns.color_palette(\"bright\")\nsns.countplot(x='satisfied', data=all_data,palette=\"Set2\")\nplt.title(\"ratio of satisfied\");","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:17:10.326598Z","iopub.execute_input":"2022-06-07T07:17:10.327600Z","iopub.status.idle":"2022-06-07T07:17:10.537092Z","shell.execute_reply.started":"2022-06-07T07:17:10.327553Z","shell.execute_reply":"2022-06-07T07:17:10.535831Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(all_data.drop(['review', 'satisfied', 'review_clean'],axis=1) ,all_data[\"satisfied\"], test_size = 0.25, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:18:50.606478Z","iopub.execute_input":"2022-06-07T07:18:50.607364Z","iopub.status.idle":"2022-06-07T07:18:51.905919Z","shell.execute_reply.started":"2022-06-07T07:18:50.607327Z","shell.execute_reply":"2022-06-07T07:18:51.904863Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestClassifier(n_estimators = 500,max_depth=None, max_features= \"auto\", random_state = 42)\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:18:54.713548Z","iopub.execute_input":"2022-06-07T07:18:54.714032Z","iopub.status.idle":"2022-06-07T07:22:54.469828Z","shell.execute_reply.started":"2022-06-07T07:18:54.714002Z","shell.execute_reply":"2022-06-07T07:22:54.468726Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"y_pred_=rf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:22:54.472118Z","iopub.execute_input":"2022-06-07T07:22:54.472614Z","iopub.status.idle":"2022-06-07T07:22:57.608138Z","shell.execute_reply.started":"2022-06-07T07:22:54.472568Z","shell.execute_reply":"2022-06-07T07:22:57.607054Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\nfrom mlxtend.plotting import plot_confusion_matrix\nconf = confusion_matrix(y_test , y_pred_)\nplot_confusion_matrix(conf)\n\n# plot_confusion_matrix(conf)\nprint (classification_report(y_test , y_pred_))","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:22:57.609750Z","iopub.execute_input":"2022-06-07T07:22:57.610240Z","iopub.status.idle":"2022-06-07T07:22:57.811361Z","shell.execute_reply.started":"2022-06-07T07:22:57.610194Z","shell.execute_reply":"2022-06-07T07:22:57.808659Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(conf, square=True, annot=True, cmap='PuBuGn', fmt='d', cbar=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:17:21.631365Z","iopub.status.idle":"2022-06-07T07:17:21.632024Z","shell.execute_reply.started":"2022-06-07T07:17:21.631676Z","shell.execute_reply":"2022-06-07T07:17:21.631707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# second approach\n## train classifiers on positive and label positive (=1) and negative Reviews with label negative (=0)","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv('../input/data-preprocessing-eda-hotel-reviews/data_hotel_reviews_clean.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:24:12.042459Z","iopub.execute_input":"2022-06-07T07:24:12.042960Z","iopub.status.idle":"2022-06-07T07:24:19.799759Z","shell.execute_reply.started":"2022-06-07T07:24:12.042916Z","shell.execute_reply":"2022-06-07T07:24:19.798588Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#loading the positive reviews and negative reviews to a single column as text\npos_reviews = df['Positive_Review_clean'].values\npos_reviews = pos_reviews.tolist()\nneg_reviews = df['Negative_Review_clean'].values\nneg_reviews = neg_reviews.tolist()\ntext = pos_reviews+neg_reviews","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:24:35.345233Z","iopub.execute_input":"2022-06-07T07:24:35.345847Z","iopub.status.idle":"2022-06-07T07:24:35.432196Z","shell.execute_reply.started":"2022-06-07T07:24:35.345798Z","shell.execute_reply":"2022-06-07T07:24:35.431002Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#providing score attribute to the review\nscore = ['positive' for i in range(len(pos_reviews))]\nscore += ['negative' for i in range(len(neg_reviews))]\n#performing one-hot encoding to the score attrubute.(1- positive and 0- negative)\nfor i in range(0,len(score)):\n    if score[i] == 'positive':\n        score[i] = 1\n    else:\n        score[i] = 0","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:24:58.870273Z","iopub.execute_input":"2022-06-07T07:24:58.870707Z","iopub.status.idle":"2022-06-07T07:24:59.149286Z","shell.execute_reply.started":"2022-06-07T07:24:58.870677Z","shell.execute_reply":"2022-06-07T07:24:59.148124Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"#loading required data to dataframe.\ntext_df = pd.DataFrame()\ntext_df['reviews_clean'] = text\ntext_df['score'] = score\ntext_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:25:00.164851Z","iopub.execute_input":"2022-06-07T07:25:00.165683Z","iopub.status.idle":"2022-06-07T07:25:01.130616Z","shell.execute_reply.started":"2022-06-07T07:25:00.165651Z","shell.execute_reply":"2022-06-07T07:25:01.128800Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# from nltk.corpus import wordnet\n\n# import string\n# from nltk import pos_tag\n# from nltk.corpus import stopwords\n# from nltk.tokenize import WhitespaceTokenizer\n# from nltk.stem import WordNetLemmatizer\n\n# def clean_text(text):\n#     # lower text\n#     text = text.lower()\n#     # tokenize text and remove puncutation\n#     text = [word.strip(string.punctuation) for word in text.split(\" \")]\n#     # remove words that contain numbers\n#     text = [word for word in text if not any(c.isdigit() for c in word)]\n#     # remove stop words\n#     stop = stopwords.words('english')\n#     text = [x for x in text if x not in stop]\n#     # remove empty tokens\n#     text = [t for t in text if len(t) > 0]\n#     # pos tag text\n#     text =[wordnet_lemmatizer.lemmatize(x) for x in text]\n#     # remove words with only one letter\n#     text = [t for t in text if len(t) > 1]\n#     # join all\n#     text = \" \".join(text)\n#     return(text)\n\n# # clean text data\n# text_df[\"reviews_clean\"] = text_df[\"reviews\"].apply(lambda x: clean_text(x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:25:17.015661Z","iopub.execute_input":"2022-06-07T07:25:17.016115Z","iopub.status.idle":"2022-06-07T07:25:17.022411Z","shell.execute_reply.started":"2022-06-07T07:25:17.016083Z","shell.execute_reply":"2022-06-07T07:25:17.020875Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"text_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-07T06:52:58.958694Z","iopub.execute_input":"2022-06-07T06:52:58.95918Z","iopub.status.idle":"2022-06-07T06:52:58.967575Z","shell.execute_reply.started":"2022-06-07T06:52:58.959133Z","shell.execute_reply":"2022-06-07T06:52:58.966215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:25:09.638088Z","iopub.execute_input":"2022-06-07T07:25:09.694026Z","iopub.status.idle":"2022-06-07T07:25:09.703072Z","shell.execute_reply.started":"2022-06-07T07:25:09.693937Z","shell.execute_reply":"2022-06-07T07:25:09.701590Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"text_df.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:25:13.915750Z","iopub.execute_input":"2022-06-07T07:25:13.916427Z","iopub.status.idle":"2022-06-07T07:25:14.114086Z","shell.execute_reply.started":"2022-06-07T07:25:13.916366Z","shell.execute_reply":"2022-06-07T07:25:14.112784Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"score = text_df['score'].values\ntext_clean=text_df[\"reviews_clean\"].values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hyperparameter tuning for MultinomialNB with Bigrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nstart_time = time.time()\nbest_params = []\nparameters = {'alpha':[i for i in range(1,100,10)]}\nacc = []\nscore = list(score)\nfor i in range(2000,14000,1000):\n    vec = TfidfVectorizer(max_features = i)\n    data = vec.fit_transform(text_clean)\n    nb = MultinomialNB()\n    clf = GridSearchCV(nb, parameters,cv=5)\n    x_train, x_test, y_train, y_test = train_test_split(data, score, test_size=0.3, random_state=42)\n    clf.fit(x_train, y_train)\n    acc.append(100.0*sum(clf.predict(x_test))/len((clf.predict(x_test))))\n    best_params.append(clf.best_params_)","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:25:19.922957Z","iopub.execute_input":"2022-06-07T07:25:19.923366Z","iopub.status.idle":"2022-06-07T07:37:03.729968Z","shell.execute_reply.started":"2022-06-07T07:25:19.923334Z","shell.execute_reply":"2022-06-07T07:37:03.728800Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"start_time = time.time()\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix , classification_report\n\n\nscore_Log_reg = []\ny_pred = clf.predict(x_test)\nconf_NB = confusion_matrix(y_test, y_pred)    \n\nprint(\"Confusion matrix:\\n\",conf_NB)\n\n#ROC for a given alpha for NB\nfrom sklearn.metrics import roc_curve, auc\n# Compute ROC curve and ROC area for each class\nprobs = clf.predict_proba(x_test)\npreds = probs[:,1]\nfpr, tpr, threshold = roc_curve(y_test, preds)\nroc_auc = auc(fpr, tpr)\n\n#Plot ROC\nimport matplotlib.pyplot as plt\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n#print the log loss\na = log_loss(y_test, probs)\nprint(\"The log loss for the Naive bayes is:\",a)\n\n\n#Precision and recall\ntn = conf_NB[0,0]; fp = conf_NB[0,1]; fn = conf_NB[1,0]; tp = conf_NB[1,1];\n\nprecision = 100*float(tp)/(tp+fp)\nrecall = 100*float(tp)/(tp+fn)\n\nprint(\"Precision :\",precision)\nprint(\"Recall :\",recall)\nprint(\"classification_report\",classification_report(y_test , y_pred))\n\ntp = conf_NB[0][0]\ntn = conf_NB[1][1]\nprint(\"The accuracy is {} %\".format(round(100.0*(tp+tn)/len(y_test),2)))\nprint('------------ %s seconds ------------'%(time.time()-start_time))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-07T07:37:03.732337Z","iopub.execute_input":"2022-06-07T07:37:03.732783Z","iopub.status.idle":"2022-06-07T07:37:05.869364Z","shell.execute_reply.started":"2022-06-07T07:37:03.732737Z","shell.execute_reply":"2022-06-07T07:37:05.867299Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## if we want to try more classifiers ","metadata":{}},{"cell_type":"code","source":"tfidf = TfidfVectorizer(max_features=10000)\ntfidf_result = tfidf.fit_transform(text_df[\"reviews_clean\"]).toarray()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tfidf_result.shape,len(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    x_train, x_test, y_train, y_test = train_test_split(tfidf_result, score, test_size=0.3, random_state=42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid={\n 'max_depth': [None],\n 'max_features': ['auto'],\n 'n_estimators': [100, 200, 300, 400]}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\n\ngrid = GridSearchCV(estimator=rf, param_grid=param_grid, n_jobs=-1,verbose=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grid_result = grid.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=grid_result.best_estimator_\nmodel_pre=model.predict(X_test)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix , classification_report\nconf = confusion_matrix(y_test , model_pre)\nfrom mlxtend.plotting import plot_confusion_matrix\nplot_confusion_matrix(conf)\nprint (classification_report(y_test , model_pre))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}